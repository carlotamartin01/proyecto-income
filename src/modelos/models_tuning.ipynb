{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3410322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13e1cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# cargamos los datasets #\n",
    "#########################\n",
    "\n",
    "X_train = pd.read_csv(\"../../data/processed/X_train.csv\")\n",
    "X_val = pd.read_csv(\"../../data/processed/X_val.csv\")\n",
    "X_test = pd.read_csv(\"../../data/processed/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../../data/processed/y_train.csv\").squeeze()\n",
    "y_val = pd.read_csv(\"../../data/processed/y_val.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"../../data/processed/y_test.csv\").squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a65862",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# funcion evaluación #\n",
    "######################\n",
    "\n",
    "'''Hace no mucho le vi esta función a dotcsv y me encantó para enseñar\n",
    "los resultados de forma clara, desde entonces me gusta usarla en todos \n",
    "mis modelos'''\n",
    "\n",
    "def mostrar_resultados(modelo, X, y, nombre):\n",
    "    predicciones = modelo.predict(X)\n",
    "    probas = modelo.predict_proba(X)[:, 1]\n",
    "    print(f\"\\nResultados de {nombre}:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y, predicciones))\n",
    "    print(\"Precision:\", precision_score(y, predicciones))\n",
    "    print(\"Recall:\", recall_score(y, predicciones))\n",
    "    print(\"F1 Score:\", f1_score(y, predicciones))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y, probas))\n",
    "    print(\"Matriz de confusión:\\n\", confusion_matrix(y, predicciones))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c0205b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# stratified cross-validation #\n",
    "###############################\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d35e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Mejores hiperparámetros para Random Forest:\n",
      "{'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "\n",
      "Resultados de Random Forest Optimizado:\n",
      "Accuracy: 0.8687230989956959\n",
      "Precision: 0.7903137039075399\n",
      "Recall: 0.6147260273972602\n",
      "F1 Score: 0.6915482783529978\n",
      "ROC AUC: 0.9253908744550633\n",
      "Matriz de confusión:\n",
      " [[7041  381]\n",
      " [ 900 1436]]\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Tuning Random Forest #\n",
    "########################\n",
    "\n",
    "#Uso de best stimator con el cv de 5 folds\n",
    "\n",
    "parametros_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "busqueda_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_distributions=parametros_rf,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_iter=20,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "\n",
    "busqueda_rf.fit(X_train, y_train)\n",
    "\n",
    "modelo_rf = busqueda_rf.best_estimator_\n",
    "print(\"Mejores hiperparámetros para Random Forest:\")\n",
    "print(busqueda_rf.best_params_)\n",
    "\n",
    "mostrar_resultados(modelo_rf, X_val, y_val, \"Random Forest Optimizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd5060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Number of positive: 7009, number of negative: 22265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 29274, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239427 -> initscore=-1.155821\n",
      "[LightGBM] [Info] Start training from score -1.155821\n",
      "Mejores hiperparámetros para LightGBM:\n",
      "{'subsample': 1.0, 'num_leaves': 31, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "\n",
      "Resultados de LightGBM Optimizado:\n",
      "Accuracy: 0.8744619799139168\n",
      "Precision: 0.7778889444722361\n",
      "Recall: 0.665667808219178\n",
      "F1 Score: 0.7174163783160323\n",
      "ROC AUC: 0.9348780975109171\n",
      "Matriz de confusión:\n",
      " [[6978  444]\n",
      " [ 781 1555]]\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#   Tuning LightGBM    #\n",
    "########################\n",
    "\n",
    "parametros_lgbm = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "busqueda_lgbm = RandomizedSearchCV(\n",
    "    estimator=LGBMClassifier(random_state=42, n_jobs=-1),\n",
    "    param_distributions=parametros_lgbm,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_iter=30,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "busqueda_lgbm.fit(X_train, y_train)\n",
    "\n",
    "modelo_lgbm = busqueda_lgbm.best_estimator_\n",
    "print(\"Mejores hiperparámetros para LightGBM:\")\n",
    "print(busqueda_lgbm.best_params_)\n",
    "\n",
    "\n",
    "mostrar_resultados(modelo_lgbm, X_val, y_val, \"LightGBM Optimizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aa97e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Guardo el mejor modelo que es el LightGBM #\n",
    "#############################################\n",
    "\n",
    "\n",
    "os.makedirs(\"../../data/models\", exist_ok=True)\n",
    "with open(\"../../data/models/modelo_lgbm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(modelo_lgbm, f)\n",
    "\n",
    "with open(\"../../data/models/modelo_rf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(modelo_rf, f)\n",
    "\n",
    "print(\"Modelos guardados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4c9a3",
   "metadata": {},
   "source": [
    "He investigado cómo ajustar los hiperparámetros de Random Forest y LightGBM usando validación cruzada para evitar overfitting. Usé una búsqueda aleatoria porque es más rápida que un grid completo y permite probar más combinaciones sin que tarde horas.\n",
    "\n",
    "Para Random Forest ajusté cosas como el número de árboles, la profundidad máxima, y cuántas muestras necesita cada hoja. El modelo final ha subido bastante en métricas como ROC AUC y precision, aunque ha bajado un poco el recall.\n",
    "\n",
    "En el caso de LightGBM, ajusté parámetros como el learning_rate, el número de hojas y cuánto se puede usar de cada columna y de cada muestra. Este modelo ha dado el mejor resultado global, con una buena combinación de todas las métricas y el ROC AUC más alto.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
